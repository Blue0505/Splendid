I0305 16:08:46.030250 140469052053312 rl_environment.py:182] Using game string: python_splendor
I0305 16:08:46.031164 140469052053312 rl_dqn.py:129] MESSAGE: 

I0305 16:08:46.031222 140469052053312 rl_dqn.py:130] Checkpoint directory: /tmp/dqn_test
I0305 16:08:46.031264 140469052053312 rl_dqn.py:131] Save every: 10000
I0305 16:08:46.031318 140469052053312 rl_dqn.py:132] Evaluate every: 5
I0305 16:08:46.031353 140469052053312 rl_dqn.py:133] Evaluate amount: 5
I0305 16:08:46.031391 140469052053312 rl_dqn.py:134] Hidden layers sizes: [64, 64]
I0305 16:08:46.031434 140469052053312 rl_dqn.py:135] Replay buffer capacity: 100000
I0305 16:08:46.031473 140469052053312 rl_dqn.py:136] Batch sizses: 32
I0305 16:08:46.031506 140469052053312 rl_dqn.py:137] Learning rate: 0.01
I0305 16:08:48.864803 140469052053312 rl_dqn.py:167] Episode: 4
I0305 16:08:48.864918 140469052053312 rl_dqn.py:168] Stats: {'p0_rewards_avg': 0.0, 'p0_rewards_std': 0.0, 'p0_rewards_max': 0.0, 'p0_rewards_min': 0.0, 'p0_game_length_avg': 131.4, 'p0_game_length_std': 15.447977213862014, 'p0_game_wins': 0, 'p1_rewards_avg': -639.5, 'p1_rewards_std': 865.3113890386512, 'p1_rewards_max': 1090.0, 'p1_rewards_min': -1121.5, 'p1_game_length_avg': 108.8, 'p1_game_length_std': 10.419213022104884, 'p1_game_wins': 1}
